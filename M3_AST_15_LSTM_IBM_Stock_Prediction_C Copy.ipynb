{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naru289/Assignment-15/blob/main/M3_AST_15_LSTM_IBM_Stock_Prediction_C%20Copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4Nwm4FK3wgU"
      },
      "source": [
        "# Advanced Programme in Deep Learning (Foundations and Applications)\n",
        "## A Program by IISc and TalentSprint\n",
        "### Assignment 15: Prediction of IBM stock price using LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxx6U-UOap7k"
      },
      "source": [
        "## Learning Objectives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxBNbT2kbDJq"
      },
      "source": [
        "   \n",
        "  At the end of the experiment, you will be able to understand:\n",
        "  * How to make predictions on time series data (IBM Stock Price) using LSTM    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlfhVGmy95YI"
      },
      "source": [
        "### Dataset Description for IBM Stock Prices\n",
        "\n",
        "The dataset contains 12 years of stock data (in the range 2006-01-01 to 2017-12-29). \n",
        "\n",
        "Note: On 30th and 31st December 2017, the days were saturday and sunday when market is closed. \n",
        "\n",
        "Moreover, the dataset contains the following columns:\n",
        "\n",
        "1. **Date** - in format: yy-mm-dd\n",
        "\n",
        "2. **Open** - represents the opening price for stock market shares that day (this is NYSE data so all in USD)\n",
        "\n",
        "3. **High** - Highest price shares reached that day\n",
        "\n",
        "4. **Low** - Lowest price for shares reached that day\n",
        "\n",
        "5. **Close** - represents the price shares ended at for the day\n",
        "\n",
        "6. **Volume** - Number of shares traded\n",
        "\n",
        "7. **Name** - the stock's ticker name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Purpose/Real-World Application\n",
        "\n",
        "The practical application of this experiment is to assist stock traders in their buying decisions by using historical data of stock pricing to identify trends and predict future prices. This product was built to provide assurance when making financial decisions."
      ],
      "metadata": {
        "id": "KOoAdvd1h17s"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "og1EHpbjgrHP"
      },
      "source": [
        "### Problem Statement\n",
        "Given the historical data of IBM stock prices(2006-2018), we need to predict the price of stock for the next day. This task can help us with better readiness with a picture of what can come next in the stock market.\n",
        "\n",
        "**Note** : To train our model, we will take past 60 days data as **Input** and predict the price of stock for the next day."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "commercial-operation"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "Sequence prediction problems have been around for a long time. They are considered as one of the hardest problems to solve in the data science industry. These include a wide range of problems; from predicting sales to finding patterns in stock markets’ data, from understanding movie plots to recognizing your way of speech, from language translations to predicting your next word on your iPhone’s keyboard.\n",
        "\n",
        "With the recent breakthroughs that have been happening in data science, it is found that for almost all of these sequence prediction problems, Long short Term Memory networks, a.k.a LSTMs have been observed as the most effective solution.\n",
        "\n",
        "LSTMs have an edge over conventional feed-forward neural networks and RNN in many ways. This is because of their property of selectively remembering patterns for long durations of time.\n",
        "\n",
        "**Long Short-Term Memory** units (LSTM) deal with the vanishing gradient problem encountered by traditional RNNs and able to remember a piece of information and keep it saved for many timesteps. This is a behavior required in complex problem domains like machine translation, speech recognition, and more.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLA8HiKxQhc"
      },
      "source": [
        "### Setup Steps:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWMVQWk58aXm"
      },
      "source": [
        "#@title Please enter your registration id to start: { run: \"auto\", display-mode: \"form\" }\n",
        "Id = \"2237180\" #@param {type:\"string\"}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwqosl928dBA"
      },
      "source": [
        "#@title Please enter your password (normally your phone number) to continue: { run: \"auto\", display-mode: \"form\" }\n",
        "password = \"6366871391\" #@param {type:\"string\"}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "GXbNUL2L6LoU",
        "outputId": "5ff0e9c3-09b5-4664-9d50-43b5b34030e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title Run this cell to complete the setup for this Notebook\n",
        "from IPython import get_ipython\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "ipython = get_ipython()\n",
        "  \n",
        "notebook= \"M3_AST_15_LSTM_IBM_Stock_Prediction_C\" #name of the notebook\n",
        "\n",
        "def setup():\n",
        "    ipython.magic(\"sx wget https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/IBM_2006-01-01_to_2018-01-01.csv\")\n",
        "    from IPython.display import HTML, display\n",
        "    display(HTML('<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId={0}&recordId={1}\"></script>'.format(getId(),submission_id)))\n",
        "    print(\"Setup completed successfully\")\n",
        "    return\n",
        "\n",
        "def submit_notebook():\n",
        "    ipython.magic(\"notebook -e \"+ notebook + \".ipynb\")\n",
        "    \n",
        "    import requests, json, base64, datetime\n",
        "\n",
        "    url = \"https://dashboard.talentsprint.com/xp/app/save_notebook_attempts\"\n",
        "    if not submission_id:\n",
        "      data = {\"id\" : getId(), \"notebook\" : notebook, \"mobile\" : getPassword()}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "\n",
        "      if r[\"status\"] == \"Success\":\n",
        "          return r[\"record_id\"]\n",
        "      elif \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None        \n",
        "      else:\n",
        "        print (\"Something is wrong, the notebook will not be submitted for grading\")\n",
        "        return None\n",
        "    \n",
        "    elif getAnswer1() and getAnswer2() and getComplexity() and getAdditional() and getConcepts() and getComments() and getMentorSupport():\n",
        "      f = open(notebook + \".ipynb\", \"rb\")\n",
        "      file_hash = base64.b64encode(f.read())\n",
        "\n",
        "      data = {\"complexity\" : Complexity, \"additional\" :Additional, \n",
        "              \"concepts\" : Concepts, \"record_id\" : submission_id, \n",
        "              \"answer1\" : Answer1, \"answer2\" : Answer2, \"id\" : Id, \"file_hash\" : file_hash,\n",
        "              \"notebook\" : notebook,\n",
        "              \"feedback_experiments_input\" : Comments,\n",
        "              \"feedback_mentor_support\": Mentor_support}\n",
        "      r = requests.post(url, data = data)\n",
        "      r = json.loads(r.text)\n",
        "      if \"err\" in r:        \n",
        "        print(r[\"err\"])\n",
        "        return None   \n",
        "      else:\n",
        "        print(\"Your submission is successful.\")\n",
        "        print(\"Ref Id:\", submission_id)\n",
        "        print(\"Date of submission: \", r[\"date\"])\n",
        "        print(\"Time of submission: \", r[\"time\"])\n",
        "        print(\"View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\")\n",
        "        #print(\"For any queries/discrepancies, please connect with mentors through the chat icon in LMS dashboard.\")\n",
        "        return submission_id\n",
        "    else: submission_id\n",
        "    \n",
        "\n",
        "def getAdditional():\n",
        "  try:\n",
        "    if not Additional: \n",
        "      raise NameError\n",
        "    else:\n",
        "      return Additional  \n",
        "  except NameError:\n",
        "    print (\"Please answer Additional Question\")\n",
        "    return None\n",
        "\n",
        "def getComplexity():\n",
        "  try:\n",
        "    if not Complexity:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Complexity\n",
        "  except NameError:\n",
        "    print (\"Please answer Complexity Question\")\n",
        "    return None\n",
        "  \n",
        "def getConcepts():\n",
        "  try:\n",
        "    if not Concepts:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Concepts\n",
        "  except NameError:\n",
        "    print (\"Please answer Concepts Question\")\n",
        "    return None\n",
        "  \n",
        "  \n",
        "# def getWalkthrough():\n",
        "#   try:\n",
        "#     if not Walkthrough:\n",
        "#       raise NameError\n",
        "#     else:\n",
        "#       return Walkthrough\n",
        "#   except NameError:\n",
        "#     print (\"Please answer Walkthrough Question\")\n",
        "#     return None\n",
        "  \n",
        "def getComments():\n",
        "  try:\n",
        "    if not Comments:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Comments\n",
        "  except NameError:\n",
        "    print (\"Please answer Comments Question\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getMentorSupport():\n",
        "  try:\n",
        "    if not Mentor_support:\n",
        "      raise NameError\n",
        "    else:\n",
        "      return Mentor_support\n",
        "  except NameError:\n",
        "    print (\"Please answer Mentor support Question\")\n",
        "    return None\n",
        "\n",
        "def getAnswer1():\n",
        "  try:\n",
        "    if not Answer1:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer1\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 1\")\n",
        "    return None\n",
        "\n",
        "def getAnswer2():\n",
        "  try:\n",
        "    if not Answer2:\n",
        "      raise NameError \n",
        "    else: \n",
        "      return Answer2\n",
        "  except NameError:\n",
        "    print (\"Please answer Question 2\")\n",
        "    return None\n",
        "  \n",
        "\n",
        "def getId():\n",
        "  try: \n",
        "    return Id if Id else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "def getPassword():\n",
        "  try:\n",
        "    return password if password else None\n",
        "  except NameError:\n",
        "    return None\n",
        "\n",
        "submission_id = None\n",
        "### Setup \n",
        "if getPassword() and getId():\n",
        "  submission_id = submit_notebook()\n",
        "  if submission_id:\n",
        "    setup() \n",
        "else:\n",
        "  print (\"Please complete Id and Password cells before running setup\")\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://dashboard.talentsprint.com/aiml/record_ip.html?traineeId=2237180&recordId=1503\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4t7tx4r7q2Y"
      },
      "source": [
        "#### Importing required packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5BV40n7Lc6s"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.optimizers import SGD\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z99_itE5J7Ec"
      },
      "source": [
        "### Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35LduRuRLlqK"
      },
      "source": [
        "dataset = pd.read_csv('/content/IBM_2006-01-01_to_2018-01-01.csv', index_col='Date', parse_dates=['Date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTRCGjC7KWOo"
      },
      "source": [
        "Let us look at few of the values from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5UFKFHlKTqu"
      },
      "source": [
        "# Getting the first five values\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3SSKyt4DVtx"
      },
      "source": [
        "# Getting the last five values\n",
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYLRshWDKlBk"
      },
      "source": [
        "Here, we can see that the IBM stock data is available till 29th December 2017(2 days short of 1st Jan 2018).\n",
        "\n",
        "Further, let us check few information related to the attributes present in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzczWju_ik8N"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMtgciigLWVz"
      },
      "source": [
        "Here, we can observe that there are 3020 entries but the column 'Open' and 'Low' has 3019 entries. This means that there are missing values in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds-sUeS6lGrP"
      },
      "source": [
        "# Sum of missing values in the dataset for all the columns\n",
        "print(dataset.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEIbJiWZZOVL"
      },
      "source": [
        "Now, let us impute the missing values with the mean values of the respective columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjj_dOvWlsgC"
      },
      "source": [
        "new_dataset = dataset\n",
        "new_dataset['Open'] = new_dataset['Open'].fillna(new_dataset['Open'].mean())\n",
        "new_dataset['Low'] = new_dataset['Low'].fillna(new_dataset['Low'].mean())\n",
        "new_dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing Stock Prices History\n",
        "\n",
        "Prior to preparing to build a LSTM model, let’s take a look at the historical prices movement of IBM by plotting a line chart."
      ],
      "metadata": {
        "id": "s1JpeCLCjf1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "plt.title('Stock Prices History')\n",
        "plt.plot(dataset['Close'])\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Prices ($)');"
      ],
      "metadata": {
        "id": "mRPCFRcJjF_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing\n",
        "\n",
        "To build a LSTM model, we need to separate our stock prices data into a training set and a test set. Besides, we will also normalize our data so that all the values are ranged from 0 to 1."
      ],
      "metadata": {
        "id": "hx2M58ckoTDb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aDdUA1VaXil"
      },
      "source": [
        "#### Preparation of training and test set\n",
        "\n",
        "Dividing the data into training set and test set. The training data consists of stock prices from 2006 to 2016 and the test set has the stock prices after 2016. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIj_3JRKLpZQ"
      },
      "source": [
        "training_set = new_dataset[:'2016'].iloc[:,1:2].values\n",
        "test_set = new_dataset['2017':].iloc[:,1:2].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tIgfeLcgRrD"
      },
      "source": [
        "# Shape of training set\n",
        "training_set.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP3kD4rMiUrN"
      },
      "source": [
        "# Shape of test set\n",
        "test_set.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC-Q4lEaIfUT"
      },
      "source": [
        "Further, let us choose 'High' attribute for prices and see what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sthb3IRIL5nv"
      },
      "source": [
        "new_dataset[\"High\"][:'2016'].plot(figsize=(16,4),legend=True)\n",
        "new_dataset[\"High\"]['2017':].plot(figsize=(16,4),legend=True)\n",
        "plt.legend(['Training set (Before 2017)','Test set (2017 and beyond)'])\n",
        "plt.title('IBM stock price')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQ9Hrdu7JPee"
      },
      "source": [
        "#### Data Normalization\n",
        "\n",
        "We will normlize the data using MinMaxScaler so that the data is in the range of 0 and 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbvMheiJL-lr"
      },
      "source": [
        "# Scaling the training set using MinMaxScaler\n",
        "sc = MinMaxScaler(feature_range=(0,1))\n",
        "training_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plE20--1Jm7z"
      },
      "source": [
        "#### Data Preparation\n",
        "\n",
        "We should input our data in the form of a 3D array to the LSTM model. Since LSTMs store long term memory state, first we create a data in 60 timesteps before using numpy to convert it into an array. Finally, we convert the data into a 3D array with X_train samples, 60 timestamps, and one feature (one output) at each step. So, for each element of training set, we have 60 previous training set elements. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn1BUOx6MBl2"
      },
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for i in range(60, 2769):\n",
        "    X_train.append(training_set_scaled[i-60:i,0])\n",
        "    y_train.append(training_set_scaled[i,0])\n",
        "X_train, y_train = np.array(X_train), np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-RpwHoeLAmp"
      },
      "source": [
        "Checking the shape of X_train and y_train in order to understand more about the structure of training features and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wezUlJxFRxgm"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIVWKC7c9tDp"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MLt6uUzRO_f"
      },
      "source": [
        "**Reshaping the data**\n",
        "\n",
        "One of the essential point to remember is that LSTM requires inputs to have shape: `[batch, timesteps, feature]`. Therefore, we will reshape the training set in certain dimensions so that it can be a valid input to the fit() function of the Sequential() model of Keras.\n",
        "\n",
        "To know more about implementing LSTM layer using Keras go through the [Keras' documentation](https://keras.io/api/layers/recurrent_layers/lstm/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMiHCmlSMCTY"
      },
      "source": [
        "# Reshaping X_train for efficient modelling\n",
        "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvn7kn5vLgNP"
      },
      "source": [
        "Checking the shape after reshaping the X_train data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ogj_Yn2R36M"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddjnTDdBMgz0"
      },
      "source": [
        "### Setting Up LSTM Network Architecture\n",
        "\n",
        "Before moving ahead with building model let us understand about LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6DRqEIY6A3f"
      },
      "source": [
        "#### **Long Short-Term Memory units (LSTM Cell)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpQP6UCK1mzS"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://cdn.iisc.talentsprint.com/DLFA/Experiment_related_data/LSTM.png\" width=\"500\" height=\"450\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsImcgfA0wed"
      },
      "source": [
        "Long Term Short Term Memory networks are an extremely powerful time-series model. They are a type of Recurrent Neural Network (RNN), that are able to learn long-term dependencies. LTSMs have been used for applying RNN’s in a variety of problems including image captioning, speech recognition, language modeling, and translation.\n",
        "\n",
        "LSTMs solve the problem of short-term memory, or vanishing and exploding gradients and gradient shrinking as a model backpropagates through time. The LSTM has gates that are able to regulate what to keep or forget/throw away. By doing so, it learns to use relevant information to make predictions. The LSTM is able to store information from the past which helps especially predict stock price fluctuations based on past prices. The market changes constantly, so making timely accurate decisions and predictions is extremely crucial for accurate results.\n",
        "\n",
        "LSTM processes data sequentially. The LSTM passes data as it propagates forward and uses gates to decide whether to keep or forget information. Each LSTM cell contains a **forget state**, **input gate**, **output gate**, and **cell state**, along with two activation functions, **Sigmoid** and **Tanh**. The **cell state** contains the long term memory, with **input gates** updating the cell state. The **forget gate** decides what information needs to be thrown away. The value 0 indicates nonessential, while 1 indicates important. The output (hidden state) is used as the prediction.\n",
        "\n",
        "**Sigmoid activation** ensures that values stay between 0 and 1. Any value multiplied by 0 is forgotten while any value multiplied by 1 is kept. \n",
        "\n",
        "**Tanh** is used to determine the candidate values to be added to the cell state. Tanh activation ensures that the values stay between a positive (1) and negative (-1) number, allowing for increase or decrease in the value for cell state.\n",
        "\n",
        "\n",
        "Now, let us build the LSTM model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# First Layer\n",
        "# The LSTM layer is added with the following arguments: \n",
        "# 20 units is the dimensionality of the output space, \n",
        "# return_sequences=True is necessary for stacking LSTM layers so the consequent LSTM layer has a \n",
        "# three-dimensional sequence input, and input_shape is the shape of the training dataset\n",
        "model.add(LSTM(units=100, input_shape=(X_train.shape[1],1), return_sequences=True))\n",
        "\n",
        "# Second Layer\n",
        "model.add(LSTM(units=100))\n",
        "\n",
        "# Third Layer\n",
        "model.add(Dense(units=25))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "CLp2aKnyuw3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training LSTM Model\n"
      ],
      "metadata": {
        "id": "r4AnwZwTrcob"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdDPenLCrIB4"
      },
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Fitting the model using X_train and y_train model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UaoRto3HscD"
      },
      "source": [
        "Creating helper function for plotting real IBM stock prices and predicted IBM stock prices. Also, creating a function for calculatin rmse value for test set and predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysssC7phLhkf"
      },
      "source": [
        "# Real IBM stock price vs predicted IBM stock price\n",
        "def plot_predictions(test,predicted):\n",
        "    plt.plot(test, color='red',label='Real IBM Stock Price')\n",
        "    plt.plot(predicted, color='blue',label='Predicted IBM Stock Price')\n",
        "    plt.title('IBM Stock Price Prediction')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('IBM Stock Price')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Function for calculating RMSE\n",
        "def return_rmse(test,predicted):\n",
        "    rmse = math.sqrt(mean_squared_error(test, predicted))\n",
        "    print(\"The root mean squared error is {}.\".format(rmse))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ndx-XWJNYxu"
      },
      "source": [
        "Before predicting future stock prices, we have to modify the test set in a similar way as the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yngkNruaMIvF"
      },
      "source": [
        "# Merge the training set and the test set on the 0 axis\n",
        "dataset_total = pd.concat((new_dataset[\"High\"][:'2016'],new_dataset[\"High\"]['2017':]), axis=0)\n",
        "# set 60 as the time step again\n",
        "inputs = dataset_total[len(dataset_total)-len(test_set) - 60:].values\n",
        "inputs = inputs.reshape(-1,1)\n",
        "inputs  = sc.transform(inputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOg8i70KN0JT"
      },
      "source": [
        "Checking the shape of the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPsCNIl-KouX"
      },
      "source": [
        "inputs.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tErssnfhOEKB"
      },
      "source": [
        "Preparing X_test and predicting the stock prices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ij3mMH2MNLD"
      },
      "source": [
        "X_test = []\n",
        "for i in range(60,311):\n",
        "    X_test.append(inputs[i-60:i,0])\n",
        "X_test = np.array(X_test)\n",
        "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))\n",
        "\n",
        "# Apply the model to predict the stock prices based on the test set\n",
        "predicted_stock_price = model.predict(X_test)\n",
        "\n",
        "# Use the inverse_transform method to denormalize the predicted stock prices\n",
        "# inverse_transform puts the stock prices in a normal readable format\n",
        "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "649muwQDOOJ3"
      },
      "source": [
        "Visualizing the results for LSTM model built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erjmfh43MU6P"
      },
      "source": [
        "plot_predictions(test_set, predicted_stock_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqNhpS5GOXJD"
      },
      "source": [
        "#### Evaluating the model\n",
        "\n",
        "Let us evaluate the LSTM model using RMSE value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXqpOEaxMZDH"
      },
      "source": [
        "# Apply the RMSE formula to calculate the degree of discrepancy between \n",
        "# the predicted prices and real prices and display the result\n",
        "return_rmse(test_set, predicted_stock_price)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2pmFJqpO-_m"
      },
      "source": [
        "Let us look at the predictions for the next day which is 1st January 2018."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN62-zilTZl6"
      },
      "source": [
        "print(f'Prediction of stock prices for the next day is {predicted_stock_price[-1,0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHfHdGCP_n6Y"
      },
      "source": [
        "### Please answer the questions below to complete the experiment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZoDc6yA_vGd"
      },
      "source": [
        "#### Consider the following statements and answer Q1.\n",
        "\n",
        "1. To generate the inputs for input and output gates. \n",
        "\n",
        "2. It helps in updating the information in such a way that there is no requirement of input and output gates.\n",
        "\n",
        "3. It is a memory unit that retains information across timesteps.\n",
        "\n",
        "4. It looks at the previous hidden state $h_{t-1}$ and the current input $x_{t}$ and outputs a number between $0$ and $1$ for each member of previous cell output $C_{t-1}$ for whether to forget."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmvdJ4aNmGjR"
      },
      "source": [
        "#@title Q.1. What is the purpose of using forget gate in LSTM? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer1 = \"Only D\" #@param [\"\",\"Only A\", \"Only B\", \"Only C\", \"Only D\"]\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNSdoU6Gqp8B"
      },
      "source": [
        "#### Consider the following statements and answer Q2.\n",
        "\n",
        "1.  Deep networks do not perform hierarchical data abstractions which enable the non-linear separation of complex data samples.\n",
        "\n",
        "2.  Deep networks perform hierarchical data abstractions which cannot perform the non-linear separation of complex data samples.\n",
        "\n",
        "3.  Deep networks perform hierarchical data abstractions which enable the non-linear separation of complex data samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX24XAeIJ6Nf"
      },
      "source": [
        "#@title Q.2. Which of the above statement(s) is true? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Answer2 = \"Statement 3\" #@param [\"\",\"Statement 2\", \"Statement 3\", \"Statement 1\", \"All of the above\"]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMzKSbLIgFzQ"
      },
      "source": [
        "#@title How was the experiment? { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
        "Complexity = \"Good and Challenging for me\" #@param [\"\",\"Too Simple, I am wasting time\", \"Good, But Not Challenging for me\", \"Good and Challenging for me\", \"Was Tough, but I did it\", \"Too Difficult for me\"]\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjcH1VWSFI2l"
      },
      "source": [
        "#@title If it was too easy, what more would you have liked to be added? If it was very difficult, what would you have liked to have been removed? { run: \"auto\", display-mode: \"form\" }\n",
        "Additional = \"NA\" #@param {type:\"string\"}\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VBk_4VTAxCM"
      },
      "source": [
        "#@title Can you identify the concepts from the lecture which this experiment covered? { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Concepts = \"Yes\" #@param [\"\",\"Yes\", \"No\"]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH91cL1JWH7m"
      },
      "source": [
        "#@title  Text and image description/explanation and code comments within the experiment: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Comments = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8xLqj7VWIKW"
      },
      "source": [
        "#@title Mentor Support: { run: \"auto\", vertical-output: true, display-mode: \"form\" }\n",
        "Mentor_support = \"Somewhat Useful\" #@param [\"\",\"Very Useful\", \"Somewhat Useful\", \"Not Useful\", \"Didn't use\"]\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FzAZHt1zw-Y-",
        "outputId": "e1853848-8329-4e0b-89a3-39176f054ff7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Run this cell to submit your notebook for grading { vertical-output: true }\n",
        "try:\n",
        "  if submission_id:\n",
        "      return_id = submit_notebook()\n",
        "      if return_id : submission_id = return_id\n",
        "  else:\n",
        "      print(\"Please complete the setup first.\")\n",
        "except NameError:\n",
        "  print (\"Please complete the setup first.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your submission is successful.\n",
            "Ref Id: 1503\n",
            "Date of submission:  06 May 2023\n",
            "Time of submission:  20:09:14\n",
            "View your submissions: https://dlfa-iisc.talentsprint.com/notebook_submissions\n"
          ]
        }
      ]
    }
  ]
}